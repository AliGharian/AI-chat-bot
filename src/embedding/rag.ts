import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { createClient } from "redis";
import { RedisVectorStore } from "@langchain/redis";
import { GoogleGenAI } from "@google/genai";
import weaviate, { WeaviateClient } from "weaviate-ts-client";
import dotenv from "dotenv";
import { WeaviateStore } from "@langchain/weaviate";
dotenv.config();

const apiKey = process.env.GEMINI_API_KEY || "";
const WEAVIATE_HOST = "84.200.192.243:8080";
const WEAVIATE_CLASS_NAME = "DocumentChunk";

export async function runSimilaritySearch(userQuery: string, k: number = 4) {
  const weaviateClient: any = weaviate.client({
    scheme: "http",
    host: WEAVIATE_HOST,
  });

  const isReady = await weaviateClient.misc.readyChecker().do();
  if (!isReady) {
    console.error("âŒ Weaviate is not ready. Cannot perform search.");
    return [];
  }
  console.log("âœ… Connected to Weaviate for search.");

  const embeddings = new GoogleGenerativeAIEmbeddings({
    model: "text-embedding-004",
    apiKey: apiKey,
  });

  const vectorStore = await WeaviateStore.fromExistingIndex(embeddings, {
    client: weaviateClient,
    indexName: WEAVIATE_CLASS_NAME,
    textKey: "content", // ğŸ’¡ Ù†Ø§Ù… ÙÛŒÙ„Ø¯ Ù…ØªÙ†ÛŒ Ø¯Ø± Schema
    metadataKeys: ["sourceKey", "metadataJson"], // ğŸ’¡ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Metadata Ø°Ø®ÛŒØ±Ù‡ Ú©Ø±Ø¯ÛŒÙ…
  });

  console.log(`Searching Weaviate for documents similar to: "${userQuery}"...`);

  // LangChain Ø¨Ø±Ø§ÛŒ Weaviate Ø§Ø² Ù…ØªØ¯ similaritySearch Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
  const results = await vectorStore.similaritySearch(userQuery, k);

  console.log(`\nğŸ” Found ${results.length} relevant documents:`);

  results.forEach((doc, index) => {
    // ğŸ’¡ Ø¯Ø± LangChain WeaviateStoreØŒ Ù…ØªØ§Ø¯ÛŒØªØ§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ doc.metadata ØªØ²Ø±ÛŒÙ‚ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    console.log(`--- Document ${index + 1} ---`);
    console.log(`Source Key: ${doc.metadata.sourceKey}`);
    // Ù…Ø­ØªÙˆØ§ÛŒ metadataJson Ø¨Ø§ÛŒØ¯ Ù¾Ø§Ø±Ø³ Ø´ÙˆØ¯ ØªØ§ Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´ÙˆØ¯
    try {
      const meta = JSON.parse(doc.metadata.metadataJson as string);
      console.log(`Title: ${meta.title}`);
    } catch (e) {
      console.log(`Title: (Metadata Parse Error)`);
    }
    console.log(`Content Snippet: ${doc.pageContent.substring(0, 150)}...`);
  });

  return results;
}

const ai = new GoogleGenAI({ apiKey: apiKey });

function formatContext(documents: any[]): string {
  const context = documents
    .map((doc) => {
      // ğŸ’¡ Ø§ØµÙ„Ø§Ø­: Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† metadataJson Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Title
      let title = "N/A";
      try {
        const meta = JSON.parse(doc.metadata.metadataJson as string);
        title = meta.title || "N/A";
      } catch (e) {
        // Ø§Ú¯Ø± Ù¾Ø§Ø±Ø³ Ù†Ø´ÙˆØ¯ØŒ Ø§Ø² N/A Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
      }

      // Ø³Ø§Ø®ØªØ§Ø±Ø¯Ù‡ÛŒ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ù‡ØªØ± ØªÙˆØ³Ø· LLM
      return `[TITLE: ${title}]\n${doc.pageContent}\n---`;
    })
    .join("\n");

  return context.trim();
}

export async function generateResponseWithRAG(userQuery: string) {
  // Ø§Ù„Ù. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ù…Ø±ØªØ¨Ø· (Ú¯Ø§Ù… Retrieval)
  const relevantDocuments = await runSimilaritySearch(userQuery, 8);
  console.log("RELEVENT DOCS IS: ", JSON.stringify(relevantDocuments));

  if (!relevantDocuments || relevantDocuments.length === 0) {
    return "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ù†Ø¨Ø¹ Ù…Ø±ØªØ¨Ø·ÛŒ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ù…Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.";
  }

  const contextText = formatContext(relevantDocuments);

  console.log("Context is: ", contextText);
  const prompt = `
        Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù…ØªØ®ØµØµ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„ Ù‡Ø³ØªÛŒØ¯. 
        ÙÙ‚Ø· Ø¨Ø± Ø§Ø³Ø§Ø³ 'CONTEXT' Ø²ÛŒØ±ØŒ Ø¨Ù‡ 'USER_QUERY' Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯. 
        Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø¬Ø§Ù…Ø¹ØŒ Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡ Ùˆ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø±ÙˆØ§Ù† Ø¨Ø§Ø´Ø¯.

        --- CONTEXT ---
        ${contextText}
        --- USER_QUERY ---
        ${userQuery}
    `;

  console.log("ğŸ“ Sending final prompt to Gemini for generation...");

  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash", // ÛŒØ§ gemini-2.5-pro
    contents: prompt,
  });

  const finalAnswer = response.text;

  console.log("âœ… Final Answer from LLM received.");
  return finalAnswer;
}
